name: "my_experiment"

speech: True # default: True

data: # specify your data here
    src: "de"  # src language: expected suffix of train files, e.g. "train.de"
    trg: "en"  # trg language
    audio: "src" # the language for the speech processing output, default: src
    audio_features_level: "mel_fb_white_et_al" # default: "mfcc", other option: "mel_fb"
    use_htk: True # use HTK formula or Slaney for for mel filters
    #scale: "None" # normalize data, default: "None", other options: "norm", "mean", "unit_var", "all"
    train: "develop/raw/head"  # training data
    dev: "develop/raw/head"  # development data for validation
    test: "develop/raw/head"  # test data for testing final model; optional
    level: "char" # segmentation level: either "word", "bpe" or "char"
    lowercase: True # lowercase the data, also for validation
    max_sent_length: 150 # filter out longer sentences from training (src+trg)
    max_audio_length: 1000 # filter out longer audio files from training
    src_voc_min_freq: 1 # src minimum frequency for a token to become part of the vocabulary
    src_voc_limit: 101  # src vocabulary only includes this many most frequent tokens, default: unlimited
    trg_voc_min_freq: 1 # trg minimum frequency for a token to become part of the vocabulary
    trg_voc_limit: 102  # trg vocabulary only includes this many most frequent tokens, default: unlimited
    #src_vocab: "my_model/src_vocab.txt"  # if specified, load a vocabulary from this file
    #trg_vocab: "my_model/trg_vocab.txt"  # one token per line, line number is index
    input_length_ratio: 100 # a possible training set's filter due to the length difference

testing:  # specify which inference algorithm to use for testing (for validation it's always greedy decoding)
    beam_size: 5  # size of the beam for beam search
    alpha: 1.0  # length penalty for beam search

training: # specify training details here
    #load_model: "my_model/3300.ckpt" # if given, load a pre-trained model from this checkpoint
    random_seed: 77 # set this seed to make training deterministic
    optimizer: "adam" # choices: "sgd", "adam", "adadelta", "adagrad", "rmsprop", default is SGD
    learning_rate: 0.001  # initial learning rate, default: 3.0e-4
    learning_rate_min: 0.00001  # stop learning when learning rate is reduced below this threshold, default: 1.0e-8
    clip_grad_val: 1.0  # clip the gradients to this value when they exceed it, optional
    #clip_grad_norm: 1.0  # norm clipping instead of value clipping
    weight_decay: 0.1 # l2 regularization, default: 0
    batch_size: 5  # mini-batch size, required
    batch_multiplier: 1 # increase the effective batch size with values >1 to batch_multiplier*batch_size without increasing memory consumption by making updates only every batch_multiplier batches
    scheduling: "plateau" # learning rate scheduling, optional, if not specified stays constant, options: "plateau", "exponential", "decaying"
    patience: 5 # specific to plateau scheduler: wait for this many validations without improvement before decreasing the learning rate
    decrease_factor: 0.5  # specific to plateau & exponential scheduler: decrease the learning rate by this factor
    epochs: 10  # train for this many epochs
    validation_freq: 5  # validate after this many updates (number of mini-batches), default: 1000
    logging_freq: 10  # log the training progress after this many updates, default: 100
    eval_metric: "bleu" # validation metric, default: "bleu", other options: "wer", "cer", "chrf", "token_accuracy", "sequence_accuracy"
    early_stopping_metric: "loss" # when a new high score on this metric is achieved, a checkpoint is written, when "eval_metric" (default) is maximized, when "loss" or "ppl" is minimized
    model_dir: "models/mini/testme_model" # directory where models and validation results are stored, required
    overwrite: True # overwrite existing model directory, default: False. Do not set to True unless for debugging!
    #shuffle: False # shuffle the training data, default: True
    use_cuda: False # use CUDA for acceleration on GPU, required. Set to False when working on CPU.
    max_output_length: 150  # maximum output length for decoding, default: None. If set to None, allow sentences of max 1.5*src length
    print_valid_sents: [0, 3, 5]  # print this many validation sentences during each validation run, default: 3
    keep_last_ckpts: 3 # keep this many of the latest checkpoints, if -1: all of them, default: 5

model:  # specify your model architecture here
    tied_embeddings: False  # tie src and trg embeddings, only applicable if vocabularies are the same, default: False
    encoder:
        rnn_type: "gru" # type of recurrent unit to use, either "gru" or "lstm", default: "lstm"
        embeddings:
            embedding_dim: 240 # size of embeddings
            scale: False  # scale the embeddings by sqrt of their size, default: False
            freeze: True  # if True, embeddings are not updated during training
        hidden_size: 256 # size of RNN
        bidirectional: True # use a bi-directional encoder, default: True
        dropout: 0.2  # apply dropout to the inputs to the RNN, default: 0.0
        num_layers: 3 # stack this many layers of equal size, default: 1
        freeze: False  # if True, encoder parameters are not updated during training (does not include embedding parameters)
        activation: "tanh" # activation type for 2 layers following the src embeddings (only for speech), default: "relu", other options: "tanh"
        last_activation: "relu" # non-linear activation after RNNs in speech encoder, default: "None", other options: "tanh", "relu"
        layer_norm: True # layer normalization layers for 2 CNNs and RNN layer, default: False
        emb_norm: False # layer normalization layers for embeddings, default: False
        same_weights: True # use same weights for linear layers, default: False
    decoder:
        rnn_type: "gru"
        embeddings:
            embedding_dim: 20
            scale: False
            freeze: False  # if True, embeddings are not updated during training
        hidden_size: 50
        dropout: 0.2
        hidden_dropout: 0.2 # apply dropout to the attention vector, default: 0.0
        num_layers: 1
        input_feeding: True # combine hidden state and attention vector before feeding to rnn, default: True
        init_hidden: "bridge" # initialized the decoder hidden state: use linear projection of last encoder state ("bridge") or simply the last state ("last") or zeros ("zero"), default: "bridge"
        attention: "bahdanau" # attention mechanism, choices: "bahdanau" (MLP attention), "luong" (bilinear attention), default: "bahdanau"
        freeze: False  # if True, decoder parameters are not updated during training (does not include embedding parameters, but attention)
